{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we'll work through constructing a convolutional neural network in Pytorch, and understanding the transformations that occur in our different layers.  We'll start by interpreting a premade neural network, and then we'll move onto constructing our own neural network let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, we'll set the device as `cuda` so that we can perform calculations on the GPU and thus speed up training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by loading our Fashion MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the `datasets` and `transforms` methods from the `torchvision` module.  Then import the FashionMNIST dataset making sure to apply the `ToTensor` transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.FashionMNIST(\"\", train = True, download = True,\n",
    "                       transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = datasets.FashionMNIST(\"\", train = False, download = True,\n",
    "                       transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's `reshape` the data so that each batch has $100$ images inside of it, and each image has one channel, with a $28x28$ grid of pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.data\n",
    "X_train_reshaped = train.data.reshape(-1, 100, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([600, 100, 1, 28, 28])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_reshaped.shape\n",
    "# torch.Size([1200, 50, 1, 28, 28])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then resize the test data into batches of 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.targets\n",
    "y_reshaped = train.targets.reshape(-1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([600, 100])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_reshaped.shape\n",
    "# torch.Size([600, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll zip together the reshaped training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = list(zip(X_train_reshaped, y_reshaped))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this [blog post](https://towardsdatascience.com/build-a-fashion-mnist-cnn-pytorch-style-efb297e22582) did the work of defining a neural network for us. \n",
    "\n",
    "It will be our task to unpack and interpret what's occurring in the different layers.\n",
    "\n",
    "Ok, let's see it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "    self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "    self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "    self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "    self.out = nn.Linear(in_features=60, out_features=10)\n",
    "\n",
    "  # define forward function\n",
    "  def forward(self, t):\n",
    "    t = self.conv1(t)\n",
    "    t = F.relu(t)\n",
    "    t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "    # conv 2\n",
    "    t = self.conv2(t)\n",
    "    t = F.relu(t)\n",
    "    t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "    # fc1\n",
    "    t = t.reshape(-1, 12*4*4)\n",
    "    t = self.fc1(t)\n",
    "    t = F.relu(t)\n",
    "    # fc2\n",
    "    t = self.fc2(t)\n",
    "    t = F.relu(t)\n",
    "    # output\n",
    "    t = self.out(t)\n",
    "    return F.log_softmax(t, dim = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now let's initialize the neural network and pass through a batch of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
       "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net\n",
    "\n",
    "# Net(\n",
    "#   (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
    "#   (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
    "#   (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
    "#   (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
    "#   (out): Linear(in_features=60, out_features=10, bias=True)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And select the first batch of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 28, 28])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch = X_train_reshaped[0]\n",
    "\n",
    "first_batch.shape\n",
    "\n",
    "# torch.Size([100, 1, 28, 28])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now let's break down what occurs at each layer.  To do so, let's select the first convolutional layer, `net.conv1` from our neural network and pass through some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 6, 24, 24])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_outputs = net.conv1(first_batch.float())\n",
    "conv_outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This data gets passed to a relu function so call `net.conv1` again, and this time pass the outputs of `conv1` to the relu function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ouput_relu_1 = F.relu(net.conv1(first_batch.float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 6, 24, 24])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ouput_relu_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Next pass the outputs of `output_relu_1` to a `max_pool2d` function with a `kernel_size` of 2 to see the change in outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 6, 12, 12])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_maxpool_1 = F.max_pool2d(ouput_relu_1, kernel_size=2, stride=2)\n",
    "output_maxpool_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this reduced the matrix from a 24 by 24 to now a 12x12 matrix.  Now that we finished with the `conv1` layer followed by a relu and a maxpool, let's move onto the `conv2` sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "    self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "    self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "    self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "    self.out = nn.Linear(in_features=60, out_features=10)\n",
    "\n",
    "  # define forward function\n",
    "  def forward(self, t):\n",
    "    t = self.conv1(t)\n",
    "    t = F.relu(t)\n",
    "    t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "    # conv 2\n",
    "    t = self.conv2(t)\n",
    "    t = F.relu(t)\n",
    "    t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "    # fc1\n",
    "    t = t.reshape(-1, 12*4*4)\n",
    "    t = self.fc1(t)\n",
    "    t = F.relu(t)\n",
    "    # fc2\n",
    "    t = self.fc2(t)\n",
    "    t = F.relu(t)\n",
    "    # output\n",
    "    t = self.out(t)\n",
    "    return F.log_softmax(t, dim = 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so let's get a sense of occurs in the next convolutional layer. \n",
    "```python\n",
    "self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again have a kernel size of 5, this time applied to an input of $12$, which we get from the preceding layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we look at how this convolutional layer is used in the forward function, we can begin to calculate the output shape that comes next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = self.conv2(t)\n",
    "t = F.relu(t)\n",
    "t = F.max_pool2d(t, kernel_size=2, stride=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we start with an output from previous sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 6, 12, 12])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_maxpool_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the `conv2` layer is executed, passed through a relu, followed by a maxpool of 2.  \n",
    "\n",
    "* `conv2 > relu > maxpool`\n",
    "\n",
    "Without using Pytorch, calculate the resulting output.  Remember that our formula for calculating the output shape is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$output = \\frac{i - k + 2p}{s} + 1$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First assign the numbers that we'll need for calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 12\n",
    "k = 5\n",
    "p = 0\n",
    "s = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Then translate the function above into code to predict the dimensions of the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(i - k + 2*p)/s + 1\n",
    "\n",
    "#  4.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So rounding down, we get a $12$ output channels, each with a 4x4 matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 12, 4, 4])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.max_pool2d(F.relu(net.conv2(output_maxpool_1)), 2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Transitioning to linear layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we keep going, we see that after our two sequences of `conv > relu > maxpool`, the next step is to pass our output to a linear layer.  To do so, we need to take our output of 12 channels each of a 4x4 matrix, and translate it to a vector of length $ 12*4*4 = 192$ feature that we pass to a linear layer.  This explains the following line in the `forward` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "t = t.reshape(-1, 12*4*4)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12*4*4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then passed this vector of 192 features is passed to a linear layer of 120 neurons, to 60 neurons to 10 neurons to pass to the `log_softmax` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now let's train our neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Initialize the Adam optimizer, passing through the parameters and the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(net.parameters(), lr=.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And fill in the middle part of the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3331, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2463, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2184, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2024, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1898, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1994, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2061, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2266, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1971, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2037, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1959, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1982, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1654, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1695, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1767, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    for X_batch, y_batch in combined:\n",
    "        preds = net(X_batch.float())\n",
    "        loss = F.cross_entropy(preds, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now that the we have trained our neural network, let's see how it performed.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The target test data is already in an adequate format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 2, 1, 1, 6])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = test.targets\n",
    "test_y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the feature data is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 28, 28])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = test.data\n",
    "test_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the `test_X` data so that each observation has a 28x28 channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_reshaped = test_X.reshape(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1, 28, 28])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X_reshaped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now get a set of predictions of the test data from the neural network, find the argmax of each prediction, and use sklearn to compute the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = net(test_X_channel.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "max_predictions = torch.argmax(predictions, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8784"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(test_y, max_predictions)\n",
    "# 0.8784"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we learned how to read through and work with a convolutional neural network in Pytorch.  We saw that we can access convolutional layers and pass data through them to find the output returned from each layer.  \n",
    "\n",
    "We can also use our formula to predict how the data will change shape as it passes through the layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$output = \\frac{i - k + 2p}{s} + 1$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw that when passing data from a convolutional layer to a linear layer, we needed to transform our data to be in the form of vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "F.max_pool2d(F.relu(net.conv2(output_maxpool_1)), 2).shape\n",
    "# torch.Size([100, 12, 4, 4])\n",
    "\n",
    "t = t.reshape(-1, 12*4*4)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we continued on with our training loop and assessing our neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "[Fashion MNist](https://towardsdatascience.com/build-a-fashion-mnist-cnn-pytorch-style-efb297e22582)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
