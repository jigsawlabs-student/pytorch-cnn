{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we could extract information about where the edges occur in each image, and then use that information as our features, instead of raw pixels?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A convolution applies  a kernel across an image. A kernel is a little matrix, such as the 3×"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "top_edge = tensor([[-1,-1,-1],\n",
    "                   [ 0, 0, 0],\n",
    "                   [ 1, 1, 1]]).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution: Perform element-wise multiplication, and after multiply together, then add them up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(im3_t[:10,:20])\n",
    "df.style.set_properties(**{'font-size':'6pt'}).background_gradient('Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> returning a high number where the 3×3-pixel square represents a top edge (i.e., where there are low values at the top of the square, and high values immediately underneath). That's because the -1 values in our kernel have little impact in that case, but the 1 values have a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Putting the 1s and -1s in columns versus rows would give us filters that detect vertical edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im3_t = tensor(im3)\n",
    "# im3_t[0:3,0:3] * top_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_kernel(row, col, kernel):\n",
    "    return (im3_t[row-1:row+2,col-1:col+2] * kernel).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(1, 1), (1, 2), (1, 3), (1, 4)],\n",
       " [(2, 1), (2, 2), (2, 3), (2, 4)],\n",
       " [(3, 1), (3, 2), (3, 3), (3, 4)],\n",
       " [(4, 1), (4, 2), (4, 3), (4, 4)]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[(i,j) for j in range(1,5)] for i in range(1,5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = range(1,27)\n",
    "left_edge = tensor([[-1,1,0],\n",
    "                    [-1,1,0],\n",
    "                    [-1,1,0]]).float()\n",
    "\n",
    "# left_edge3 = tensor([[apply_kernel(i,j,left_edge) for j in rng] for i in rng])\n",
    "\n",
    "# show_image(left_edge3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Convolution Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* So convolution can just tell us where the edges are.\n",
    "* The output of a convolution is called a channel\n",
    "* And maybe one channel finds top edges, and another finds left, and then combines to find top left."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./padding.png\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll want different kernels.  And we'll want them finding different features, so we want to create a 3x3x3 kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But ultimately, this 3x3x3 will create just one number, because elementwise multiplication and then add them all up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Strides\n",
    "\n",
    "Now lot's of times, we might not go over every single pixel, because our memory will go out of control.  So we hop over pixels.  And if hop over two pixels after after convolution, called a stride 2 convolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2, 2), (2, 4), (2, 6), (2, 8)\n",
    "\n",
    "* And this leads to half as many convolutions, so then can double the number of kernels.  So now h/2 and w/2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padding should be kernel size divide by 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 3x3 kernel can't really handle edges, because can't go any further.\n",
    "\n",
    "### Pytorch Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The PyTorch docs tell us that it includes these parameters:\n",
    "\n",
    "* input:: input tensor of shape (minibatch, in_channels, iH, iW)\n",
    "* weight:: filters of shape (out_channels, in_channels, kH, kW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* iH,iW is the height and width of the image (i.e., 28,28), and kH,kW is the height and width of our kernel (3,3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Pytorch Tricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The first trick is that PyTorch can apply a convolution to multiple images at the same time. That means we can call it on every item in a batch at once!\n",
    "\n",
    "2. The second trick is that PyTorch can apply multiple kernels at the same time. So let's create the diagonal-edge kernels too, and then stack all four of our edge kernels into a single tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "diag1_edge = tensor([[ 0,-1, 1],\n",
    "                     [-1, 1, 0],\n",
    "                     [ 1, 0, 0]]).float()\n",
    "diag2_edge = tensor([[ 1,-1, 0],\n",
    "                     [ 0, 1,-1],\n",
    "                     [ 0, 0, 1]]).float()\n",
    "\n",
    "edge_kernels = torch.stack([left_edge, top_edge, diag1_edge, diag2_edge])\n",
    "edge_kernels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> PyTorch represents an image as a rank-3 tensor, with dimensions [channels, rows, columns]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the average of each (phase?) or convolution, and call Average2d with output size of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the convolutions represents a different feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Arithemtic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[cnn arithemetic](http://deeplearning.net/software/theano/tutorial/conv_arithmetic.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "[Guide to Convolution](https://arxiv.org/abs/1603.07285)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Setosa image kernels](https://setosa.io/ev/image-kernels/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Fast ai youtube CNN](https://youtu.be/hkBa9pU-H48?list=PLfYUBJiXbdtSIJb-Qd3pw0cqCbkGeS0xn&t=4265)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
